\chapter{Objetivos y planteamiento de la solución}
\label{cap:Objetivos y planteamiento de la solución}
En este capítulo, se abordarán los objetivos y requisitos esenciales del sistema propuesto en este trabajo, así como las restricciones que deben tenerse en cuenta. A continuación, se presentará el planteamiento inicial del sistema, incluyendo un análisis de la arquitectura general y la identificación de las herramientas necesarias para su desarrollo. Además, se llevará a cabo una evaluación exhaustiva de las diferentes opciones disponibles para la implementación del sistema, junto con las consideraciones que respaldan las decisiones de implementación adoptadas.

\section{APIs}

%No sé incluso si no hacerlo un propio cápitulo de la elección de API ya que ha sido 3 meses dedicado a la investigación de qué api usar


%Pasar todas las APIs de las que se hablo en el otro sitio 

%Hablar de las VPN y de la aplicación que se ha usado para eso mismo

%Finalmente poner capturas de consultas a la api de gemini, la estructura de las respuestas, analizar los diferentes modelos, decir porque se ha elegido gemini pro


%Decir ventajas poniendo capturas de preguntas y respuestas que da gemini 
%También hablar de las limitaciones 

\section{Software y herramientas}



\subsection{Entorno de ejecución}
\subsection{Librerías utilizadas}
%Expresiones regulares

\subsection{RDF}

El Resource Description Framework (RDF) es un modelo estándar para describir recursos en la web semántica. En RDF, la información se representa en forma de tripletas, que consisten en un sujeto, un predicado y un objeto. Estas tripletas se pueden usar para modelar datos de una manera semántica y enlazada, lo que facilita su interpretación por parte de las máquinas.




En el Listado , se muestra un ejemplo de tripletas RDF en formato Turtle. Aquí, se describe que "Juan" es amigo de "María" y ambos son de tipo "Persona".

\subsection{Uso de RDFLib en Python}

Para trabajar con tripletas RDF en Python, podemos utilizar la biblioteca RDFLib. A continuación, se muestra un ejemplo de cómo crear y manipular un grafo RDF utilizando RDFLib:


%Aquí quiero poner código de tripletas RDF que muestre las funcionalidades que yo he usado 

\begin{lstlisting}[frame=tb]
g = Graph()
 \end{lstlisting}

Uno de los beneficios clave de las tripletas RDF es su flexibilidad en la representación de datos. No están limitadas a un esquema predefinido, lo que significa que pueden adaptarse fácilmente a diferentes tipos de conversaciones y contextos terapéuticos. Esto permite que el chatbot capture una amplia gama de información de manera estructurada y significativa.
	
Las tripletas RDF promueven la interoperabilidad y la reutilización de datos al utilizar estándares abiertos y enlazados. Esto significa que la información almacenada en un formato RDF puede ser compartida, integrada y enriquecida con datos externos de manera más eficiente. En el contexto de la terapia de reminiscencia, esto podría traducirse en la capacidad de acceder a una amplia gama de recursos y experiencias compartidas por diferentes individuos o comunidades.
	
La estructura de tripletas RDF facilita la consulta y el análisis de datos, lo que permite al chatbot realizar búsquedas avanzadas, generar estadísticas y ofrecer recomendaciones personalizadas. Esto puede mejorar significativamente la experiencia del usuario al proporcionar respuestas relevantes y contextualizadas durante las sesiones de terapia de reminiscencia.

	

	
En conclusión, las tripletas RDF ofrecen una solución sólida y versátil para el almacenamiento de información en el contexto de la terapia de reminiscencia. Su capacidad para modelar semánticamente los datos, su flexibilidad en la representación, su interoperabilidad y su facilidad de consulta hacen que sean una opción ideal para el desarrollo de chatbots de ayuda a la terapia de reminiscencia. Al aprovechar estas ventajas, se puede mejorar la calidad y efectividad de la interacción entre el chatbot y los usuarios, contribuyendo así a mejorar su bienestar emocional y cognitivo.
	
\subsection{Arquitectura del sistema}


\section{Procesamiento del lenguaje}

%Sobre NLTK y el procesamiento del lenguaje use este enlace: https://www.ibm.com/es-es/topics/natural-language-processing#:~:text=El%20procesamiento%20del%20lenguaje%20natural%20(NLP)%20hace%20referencia%20a%20la,manera%20que%20los%20seres%20humanos.

El Procesamiento del Lenguaje Natural (NLP) es una rama de la informática que se enfoca en proporcionar a los sistemas informáticos la capacidad de entender y procesar textos y palabras habladas de manera similar a los seres humanos. Combina la lingüística computacional con modelos estadísticos, de machine learning y deep learning para permitir a las máquinas comprender el significado completo, la intención y el sentimiento detrás del lenguaje humano, ya sea en forma de texto o voz.

NLP impulsa una amplia gama de aplicaciones, desde la traducción automática hasta la respuesta a órdenes habladas, pasando por la atención al cliente mediante chatbots. Además, está ganando cada vez más popularidad, tanto a nivel particular cómo empresarial, médico, etc. 

Hasta hace unos años, el procesamiento del lenguaje en Python se hacía utilizando diferentes bibliotecas como NLTK o Spacy. Sin embargo, en los últimos años se han desarrollado númerosos modelos de chatbots.

\subsection{Bibliotecas de Python}
\subsubsection{NLTK}
Python, un lenguaje de programación popular, cuenta con una amplia variedad de herramientas y bibliotecas para abordar tareas específicas de NLP. Una de las bibliotecas más destacadas es el kit de herramientas de lenguaje natural (NLTK), una colección de recursos de código abierto que facilita la creación de programas de NLP.

NLTK ofrece una amplia gama de funcionalidades, incluyendo el análisis de oraciones, segmentación de palabras, etiquetado gramatical, radicación y lematización, así como el reconocimiento de voz y la generación de lenguaje natural. También proporciona herramientas para el razonamiento semántico y la comprensión del texto. Esta biblioteca es ampliamente utilizada en la comunidad de NLP debido a su versatilidad y facilidad de uso en proyectos de procesamiento de lenguaje.
\subsubsection{SpaCy}
SpaCy es una biblioteca de procesamiento del lenguaje natural (NLP) en Python, lanzada en 2015 por Matt Honnibal. Ofrece soporte para más de 70 idiomas y cuenta con modelos preentrenados como BERT. Sus características incluyen tokenización, reconocimiento de entidades nombradas y análisis de dependencia. Comparada con NLTK, spaCy es más rápida y precisa, mientras que Gensim y TensorFlow/Keras complementan sus funcionalidades. Sus capacidades lingüísticas abarcan etiquetado de partes de discurso, análisis de dependencia, reconocimiento de entidades y más.
\subsection{APIs de procesamiento del lenguaje natural}
Las APIs de procesamiento del lenguaje son conjuntos de herramientas y servicios que permiten a los desarrolladores integrar capacidades de procesamiento del lenguaje natural (NLP) en sus aplicaciones y sistemas. Estas APIs ofrecen funcionalidades como análisis de sentimientos, reconocimiento de entidades nombradas, etiquetado de partes del discurso, traducción automática, resumen de texto, entre otros. Al utilizar una API de procesamiento del lenguaje, los desarrolladores pueden aprovechar las capacidades avanzadas de NLP sin necesidad de desarrollar desde cero sus propios algoritmos y modelos. Esto facilita la implementación de características de procesamiento del lenguaje en una amplia variedad de aplicaciones, desde chatbots hasta análisis de redes sociales y sistemas de recomendación.

Las APIs modernas suelen contar con todas las funcionalidades que contaban las bibliotecas de Python mencionadas anteriormente. En concreto, para el desarrollo de este proyecto se estudiaron las APIs que se presentan a continuación.

\subsubsection{Bard}
En primer lugar, para realizar la tarea de procesamiento de la información y análisis del lenguaje se utilizo la API de Bard. La API de Bard ofrece a los desarrolladores una herramienta poderosa para el procesamiento de lenguaje natural y la generación de texto. Sus características clave incluyen la capacidad de producir texto coherente y relevante, adaptado al contexto específico de la aplicación. Además, permite una personalización flexible de la salida de texto para satisfacer las necesidades individuales de cada usuario. Gracias a su integración con modelos de lenguaje avanzados, la API de Bard es capaz de generar resultados de alta calidad en múltiples idiomas y estilos de escritura. Su interfaz fácil de usar y su versatilidad hacen que sea una opción ideal para una amplia gama de aplicaciones de NLP.

En diciembre de 2023, Google fortaleció la capacidad de Bard al incorporar Gemini Pro en inglés, brindando habilidades más avanzadas de comprensión, razonamiento, resumen y codificación. Posteriormente, en febrero de 2024, se anunció la expansión de Gemini Pro a más de 40 idiomas y se oficializó el cambio de nombre de Bard a Gemini, con lo que se tuvo que descartar el primer modelo del proyecto desarrollado en Bard, y tampoco se pudo volcar a Gemini ya que, por el momento, no está disponible en España. 

\subsubsection{Rasa}
Entre las opciones que se barajaron para seguir desarrollando el proyecto se encuentra Rasa. Rasa es una plataforma de código abierto diseñada para el desarrollo de chatbots y asistentes virtuales conversacionales. Utilizando técnicas de procesamiento de lenguaje natural (NLP) y aprendizaje automático, Rasa permite a los desarrolladores crear sistemas de diálogo inteligentes y personalizados. Una de las principales ventajas de Rasa es su flexibilidad y personalización, ya que los desarrolladores tienen control total sobre el comportamiento y la lógica de sus chatbots. Además, Rasa proporciona herramientas robustas para la gestión del diálogo, la comprensión del lenguaje natural y la integración con otros sistemas. Sin embargo, una posible desventaja de Rasa es su curva de aprendizaje, ya que requiere un conocimiento sólido de NLP y aprendizaje automático para aprovechar al máximo su potencial. Además, debido a su naturaleza de código abierto, puede requerir más tiempo y recursos para implementar y mantener en comparación con otras soluciones comerciales.
\subsubsection{GPT}
La API de ChatGPT ofrece una solución altamente adaptable y fácil de usar para la generación de texto conversacional, proporcionando respuestas coherentes y contextualmente relevantes que imitan de manera natural las interacciones humanas. Su versatilidad la hace adecuada para una amplia gama de aplicaciones, desde chatbots de atención al cliente hasta asistentes virtuales y juegos de texto, y su escalabilidad y medidas de seguridad robustas garantizan un rendimiento confiable y protección de datos en cualquier entorno de implementación. Sin embargo para obtener el comportamiento que se necesitaba en este trabajo debía ser entrenada, y debido a las limitaciones hardware esto suponía una cantidad de tiempo inviable. 
\subsection{Gemma}
Gemma es una herramienta de código abierto que ofrece capacidades avanzadas para la generación de texto y el procesamiento de lenguaje natural (NLP). Durante su evaluación, se probaron los modelos Gemma-2b y Gemma-7b, descargados de Hugging Face, en un entorno de sistema operativo Linux para optimizar su rendimiento. Aunque Gemma se destacó como la mejor opción disponible hasta el momento, se encontraron limitaciones relacionadas con el tamaño del modelo y algunas restricciones adicionales. 
\subsection{Gemini}
Finalmente, se decidio utilizar la API de Gemini descartada en un primer momento por no estar disponible en España. Por tanto, para su uso, y en consecuencia para hacer funcionar el proyecto es necesario tener una VPN conectada a uno de los países en los que Gemini esta disponible. Una vez conectado se ha de obtener una API KEY y configurar el proyecto adecuadamente. Durante el resto de uso del programa, sigue siendo necesario estar conectado a la VPN.
\section{Almacenamiento de la información}
\subsection{Conclusión final}